input { pipeline { address => auth } }

filter {
  mutate {
    add_field  => {"[event][dataset]" => "auth"}
  }

  mutate {
    rename => {"@timestamp" => "[event][created]"}
  }

  mutate { gsub => ["message", "\n", ","] }
  mutate { gsub => ["message", "\t", " "] }

  grok {
    match => { "message" => "%{DAY:day_of_week}%{SPACE}%{MONTH:month} %{MONTHDAY:month_day} %{TIME:time} %{YEAR:year}, %{GREEDYDATA:message}"}
    overwrite => [ "message" ]
  }

  mutate { rename => {"@timestamp" => "[event][created]"} }
  mutate { add_field => { "[@metadata][timestamp]" => "%{month} %{month_day} %{year} %{time}" } }
  mutate { remove_field => ["month", "month_day", "year", "time"] }
  date { match => [ "[@metadata][timestamp]", "MMM dd YYYY HH:mm:ss" ] }

  kv {
    field_split_pattern => ", "
    value_split_pattern => " = "
    # transform_key => "lowercase"
    target => "auth"
  }

  kv {
    source => "[auth][NAS-Port-Id]"
    field_split_pattern => ";"
    value_split_pattern => "="
    target => "[auth][NAS-Port-Id]"
  }

  if [auth][Called-Station-Id] {

    grok {
      match => { "[auth][Called-Station-Id]" => "(?<[@metadata][ap_mac]>^.{0,17})"}
    }

    jdbc_static {
      loaders => [ 
        {
          id => "sqlite_ap_list"
          query => "select Name, MAC, AP_Group from ap_list"
          local_table => "ap_list"
        }
      ]
      local_db_objects => [ 
        {
          name => "ap_list"
          index_columns => ["Name"]
          columns => [
            ["Name", "varchar(255)"],
            ["MAC", "varchar(255)"],
            ["AP_Group", "varchar(255)"]
          ]
        }
      ]
      local_lookups => [ 
        {
          id => "local-ap-list"
          query => "SELECT Name as name, AP_Group as ap_group FROM ap_list WHERE MAC = :mac"
          parameters => {"mac" => "%{[@metadata][ap_mac]}"}
          target => "access_point"
        }
      ]

      # using add_field here to add & rename values to the event root
      # add_field => { name => "%{[_ap][0][name]}" } 
      # add_field => { ap_group => "%{[_ap][0][ap_group]}" }
      # remove_field => ["_ap"]
      staging_directory => "/tmp/logstash/jdbc_static/import_data"
      loader_schedule => "0 1 * * *" # run loaders every day at 1:00am
      jdbc_user => ""
      jdbc_password => ""
      jdbc_driver_class => "org.sqlite.JDBC"
      jdbc_driver_library => "/opt/logstash/sqlite-jdbc-3.18.0.jar"
      jdbc_connection_string => "jdbc:sqlite:/opt/logstash/ap_list.db"
    }

    if ![access_point][0][name] {
      mutate {
        add_tag => [ "access_point_not_found" ]
      }
    }

  }

}

output {
  elasticsearch {
    hosts => {{ elasticsearch_hosts }}
    manage_template => false
    index => "auth-%{+YYYY.MM}"
    user => elastic
    password => {{ elasticsearch_password }}
    ecs_compatibility => disabled
  }
}